---
title: "basic_modeling"
output: html_document
date: "2025-01-20"
---
This is the initial modeling analyses for study 2.

The setup was:
4 spatial recall practice
4 digit span practice
4 rest practice

10 groups, 13 blocks per group
- 10 digit span per block
- 10 visual search per block
- up to 20 rest per rest period

group ordering: ABABBABAAB

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library("knitr") # for knitting things
library("tidyverse") # for all things tidyverse
library("broom")      # for tidying up linear models 
library("car")        # for running ANOVAs
library("afex")       # also for running ANOVAs
library("emmeans")    # for calculating constrasts
library(jsonlite)

# set the default ggplot theme 
theme_set(theme_classic())
```

# READ IN DATA (these are all post-exclusion files from both batches)
``` {r data_loading}
# exp vars
sr_practice_num <- 4
sr_per_block <- 10
ds_practice_num <- 4
ds_per_block <- 10
rt_practice_num <- 4
rt_per__block_max <- 20
num_groups <- 10
num_blocks_per_group <- 3
num_blocks_overall <- num_groups * num_blocks_per_group

df_all <- read.csv("/Users/nastasiaklevak/Desktop/FYP_2024/CognitiveFatigue_TaskSpecificity/data_anonymized/SPRmain/excluded/SPRmain_main_trials_cleaned.csv",stringsAsFactors = FALSE) %>%
  select(-X)
df_practice <- read.csv("/Users/nastasiaklevak/Desktop/FYP_2024/CognitiveFatigue_TaskSpecificity/data_anonymized/SPRmain/excluded/SPRmain_practice_trials_cleaned.csv",stringsAsFactors = FALSE)%>%
  select(-X)
df_survey <- read.csv("/Users/nastasiaklevak/Desktop/FYP_2024/CognitiveFatigue_TaskSpecificity/data_anonymized/SPRmain/excluded/SPRmain_survey_cleaned.csv", stringsAsFactors = FALSE)%>%
  select(-X)
```

# QUESTION 1:
1) Is there a post-error increase in fatigue? i.e. is accuracy a significant negative estimator for subsequent rest time?

**model idea**: Rest Time (rests taken in a given chunk) ~ Average accuracy in previous block + time(block_num) + game_type + group_num(represents place in experiment) + gameA_isSR(which order the games were in) + (1|subject)

``` {r data_loading}
# get average per block per subject
rest_info <- df_all %>%
  filter(!is.na(rest_chunk), !is.na(type_desc)) %>%
  select(block_num = rest_chunk, num_rest_in_chunk, rest_type = type_desc) %>%
  distinct() %>%
  group_by(block_num) %>%
  slice(1)  # Take only the first row for each block
# Then join with summary
df_all_blockwise <- df_all %>%
  ungroup() %>%
  filter(trial_type != "rt_main_trials") %>%
  group_by(subj_id, block_num) %>%
  summarize(
    avg_block_accuracy = mean(is_correct_numeric),
    accuracy_sd = sd(is_correct_numeric),
    avg_rt = mean(rt[!timed_out]),
    rt_sd = sd(rt[!timed_out]),
    group_num = first(group_num),
    gameA_isSR = first(gameA_isSR),
    game_type = first(game_type),
    .groups = 'drop'
  ) %>%
  left_join(rest_info, by = "block_num") %>%
  mutate(cue_type = ifelse(rest_type == "block_same_same" | rest_type == "group_A_A" | rest_type == "group_B_B", "stay", "switch"))

df_all_blockwise <- df_all_blockwise %>%
  group_by(subj_id) %>%
  mutate(scale_rest = as.vector(scale(num_rest_in_chunk, center = TRUE, scale = TRUE)),
         scale_accuracy = as.vector(scale(avg_block_accuracy, center = TRUE, scale = TRUE))) %>%
  ungroup()
```

``` {r q1_analysis}
df_all_blockwise %>%
  ggplot(mapping = aes(x = avg_block_accuracy, y = num_rest_in_chunk)) +
  geom_smooth(method="lm",se=TRUE) +
  geom_point(mapping = aes(color = block_num), size = 2) +  # Points colored by block number
  labs(x = "Average block accuracy",
       y = "Scaled number of rest taken",
       color = "Block Number") +
  ggtitle("Predicting rest length from performance")


df_all_blockwise %>%
  ggplot(mapping = aes(x = scale_accuracy, y = scale_rest)) +
  geom_smooth(method="lm",se=TRUE) +
  geom_point(mapping = aes(color = block_num), size = 2) +  # Points colored by block number
  labs(x = "Scaled avg block accuracy",
       y = "Scaled number of rest taken",
       color = "Block Number") +
  ggtitle("Predicting rest length from performance")
```

``` {r q1_analysis}
# adding the r squared value to the plot
# First create the linear model to get R-squared
lm_model <- df_all_blockwise %>%
  lm(num_rest_in_chunk ~ avg_block_accuracy, data = .)

# Get R-squared value formatted nicely
summary(lm_model)
r_squared <- summary(lm_model)$r.squared
r_squared_label <- sprintf("R² = %.3f", r_squared)
print(r_squared)

# Create the plot with R-squared annotation
df_all_blockwise %>%
  ungroup() %>%
  ggplot(mapping = aes(x = avg_block_accuracy, y = num_rest_in_chunk)) +
  geom_smooth(method = "lm", se = TRUE) +
  geom_point(mapping = aes(color = block_num), size = 1, position=position_jitter(0,0.1), alpha = 0.6) +
  annotate("text", 
           x = 0.1,  # Try middle of x-axis
           y = 3,    # Try near top of y-axis
           label = r_squared_label) +
  labs(x = "Average block accuracy",
       y = "Following rest number taken",
       color = "Block Number") +
  ggtitle("Predicting rest length from performance")


################## scaled version ################################################
# adding the r squared value to the plot
# First create the linear model to get R-squared
lm_model <- df_all_blockwise %>%
  lm(scale_rest ~ scale_accuracy, data = .)

# Get R-squared value formatted nicely
summary(lm_model)
r_squared <- summary(lm_model)$r.squared
r_squared_label <- sprintf("R² = %.3f", r_squared)
print(r_squared)

df_all_blockwise %>%
  ungroup() %>%
  ggplot(mapping = aes(x = scale_accuracy, y = scale_rest)) +
  geom_smooth(method="lm",se=TRUE) +
  geom_point(mapping = aes(color = block_num), size = 1, position=position_jitter(0,0.1), alpha = 0.6) +  # Points colored by block number
  annotate("text", 
           x = 0.1,  # Try middle of x-axis
           y = 3,    # Try near top of y-axis
           label = r_squared_label) +
  labs(x = "Scaled avg block accuracy",
       y = "Scaled number of rest taken",
       color = "Block Number") +
  ggtitle("Predicting rest length from performance")
```
``` {r q1_analysis}
# Separate regression lines for each block
ggplot(df_all_blockwise, aes(x = avg_block_accuracy, y = scale_rest, color = factor(block_num))) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE) +
  labs(x = "Average block accuracy",
       y = "Following rest number taken",
       color = "Block Number") +
  ggtitle("Relationship between performance and scaled rests taken by block")

# Separate regression lines for each group
ggplot(df_all_blockwise, aes(x = avg_block_accuracy, y = scale_rest, color = factor(group_num))) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = TRUE) +
  labs(x = "Average block accuracy",
       y = "Following rest number taken",
       color = "Group Number") +
  ggtitle("Relationship between performance and scaled rests taken by group")
```
``` {r q1_analysis}
# Evolution of accuracy-rest relationship across blocks
df_all_blockwise %>%
  group_by(subj_id) %>%
  # mutate(
  #   acc_centered = scale(avg_block_accuracy, center = TRUE, scale = FALSE),
  #   rest_centered = scale(num_rest_in_chunk, center = TRUE, scale = FALSE)
  # ) %>%
  ggplot(aes(x = block_num, y = scale_rest, color = scale_accuracy)) +
  geom_point(alpha = 0.3, position=position_jitter(0.1)) +
  geom_smooth(method = "loess") +
  scale_color_gradient2(low = "red", mid = "white", high = "blue", 
                       midpoint = 0,
                       name = "Relative\nAccuracy") +
  labs(x = "Block Number",
       y = "Relative rest num",
       title = "How Performance Affects Fatigue Across Task Progress",
       subtitle = "Blue = better than subject's average, Red = worse") +
  theme_minimal()

df_all_blockwise %>%
  ungroup() 
```

``` {r q1_analysis}
### plotting the betas of the coefficients
# Calculate block-specific betas
block_betas <- df_all_blockwise %>%
  group_by(block_num) %>%
  summarise(
    model = list(lm(scale_rest ~ avg_block_accuracy)),
    tidy_model = list(tidy(model[[1]])),
    r2 = summary(model[[1]])$r.squared
  ) %>%
  unnest(tidy_model) %>%
  filter(term == "avg_block_accuracy") %>%
  mutate(
    ci_lower = estimate - 1.96 * std.error,
    ci_upper = estimate + 1.96 * std.error,
    significant = p.value < 0.05
  )

# Create the plot
ggplot(block_betas, aes(x = block_num)) +
  # Add horizontal line at y=0 for reference
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  # Add linear trend line
  geom_smooth(aes(y = estimate), method = "lm", color = "red", alpha = 0.2) +
  # Add error bars
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2) +
  # Add points, colored by significance
  geom_point(aes(y = estimate, color = significant), size = 3) +
  # Add line connecting points
  geom_line(aes(y = estimate), alpha = 0.5) +
  # Color scheme
  scale_color_manual(values = c("gray60", "blue"), 
                    labels = c("p ≥ 0.05", "p < 0.05")) +
  # Labels
  labs(x = "Block Number",
       y = "Beta Coefficient (Z-Rest_number ~ Accuracy)",
       title = "How Performance Predicts Subsequent Bids Across Blocks",
       subtitle = "Red line shows linear trend across blocks",
       color = "Statistical\nSignificance") +
  theme_minimal() +
  theme(
    panel.grid.minor = element_blank(),
    axis.title = element_text(face = "bold")
  )

# Calculate and print trend statistics
trend_model <- lm(estimate ~ block_num, data = block_betas)
trend_summary <- summary(trend_model)

# Print key statistics
cat("\nLinear Trend Analysis:\n")
cat("Slope:", round(coef(trend_model)[2], 3), "\n")
cat("p-value:", round(trend_summary$coefficients[2,4], 3), "\n")
cat("R-squared:", round(trend_summary$r.squared, 3), "\n")
```

``` {r q1_analysis}
#TODO: look at this ^ but by game type
```

``` {r q1_analysis}
# Create the linear model to get R-squared and effect size
lm_model <- df_all_blockwise %>%
  ungroup() %>%
  lm(scale_rest ~ scale_accuracy, data = .)

# Get R-squared value
r_squared <- summary(lm_model)$r.squared
r_squared_label <- sprintf("R² = %.3f", r_squared)
p_value <- anova(lm_model)$"Pr(>F)"[1]

# Calculate Cohen's f² effect size
# f² = R² / (1 - R²)
f_squared <- r_squared / (1 - r_squared)

# For simple regression, we can convert r to d
# First get r (correlation)
r <- sqrt(r_squared) * sign(coef(lm_model)[2])  # multiply by sign of slope
# Convert r to d using the formula: d = 2r/sqrt(1-r^2)
cohens_d <- (2 * r) / sqrt(1 - r^2)

# Create formatted labels
stats_label <- sprintf("R² = %.3f\nf² = %.3f\nd = %.3f\np = %.3e", 
                      r_squared, f_squared, cohens_d, p_value)
df_all_blockwise %>%
  ggplot(mapping = aes(x = scale_accuracy, y = scale_rest)) +
  geom_smooth(method="lm", se=TRUE) +
  geom_point(mapping = aes(color = block_num), size = 2) +
  scale_x_reverse() +  # Flip x-axis
  annotate("text", 
           x = 4,  
           y = 1.75,
           label = stats_label,
           size = 3) +  # Larger text
  labs(x = "Scaled Average block accuracy",
       y = "Scaled rests taken",
       color = "Block Number") +
  ggtitle("Predicting rest from performance") +
  theme_bw() +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    plot.title = element_text(size = 16),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )
```

``` {r q1_analysis}
# TODO do REACTION TIME (i.e. RT variability, etc)
```

``` {r q1_analysis_models_nonRT}
# **model idea**: Rest Time (rests taken in a given chunk) ~ Average accuracy in previous block + time(block_num) + game_type + group_num(represents place in experiment) + gameA_isSR(which order the games were in) + (1|subject)
# complete_data_rest_models <- na.omit(df_all_blockwise) # this gets rid of timed out trials where rt_sd = NaN

#until we use RT, maybe just get rid of the RT columns OR filter out the timed_out
# 1) get rid of RT cols and do this
library(MASS, exclude = "select")

complete_data_rest_models_noRT <- df_all_blockwise %>%
  select(-avg_rt, -rt_sd)

complete_data_rest_models_noRT <- na.omit(complete_data_rest_models_noRT)

# # using poisson bc it's count data (rest number) -> fails to converge
# fit.rest_noRT_one <- glmer(num_rest_in_chunk ~ (1|subj_id),
#                            data = complete_data_rest_models_noRT,
#                            family = poisson)

# using a regular negative binomial (only fixed effects though, so modeling PER subject)
# center the group_num and block_num to reduce collinearity: 
complete_data_rest_models_noRT$group_num_centered <- 
    as.vector(scale(complete_data_rest_models_noRT$group_num, center=TRUE, scale=FALSE))
complete_data_rest_models_noRT$block_num_centered <- 
    as.vector(scale(complete_data_rest_models_noRT$block_num, center=TRUE, scale=FALSE))

# run the models:
fit.rest_noRT_one <- glm.nb(num_rest_in_chunk ~ factor(subj_id),
                           data = complete_data_rest_models_noRT)
fit.rest_noRT_two <- glm.nb(num_rest_in_chunk ~ block_num_centered + factor(subj_id),
                           data = complete_data_rest_models_noRT)
fit.rest_noRT_three <- glm.nb(num_rest_in_chunk ~ block_num_centered + factor(subj_id),
                           data = complete_data_rest_models_noRT)
fit.rest_noRT_four <- glm.nb(num_rest_in_chunk ~ block_num_centered + avg_block_accuracy + factor(subj_id),
                           data = complete_data_rest_models_noRT)
fit.rest_noRT_five <- glm.nb(num_rest_in_chunk ~ block_num_centered*avg_block_accuracy + factor(subj_id),
                           data = complete_data_rest_models_noRT)
fit.rest_noRT_six <- glm.nb(num_rest_in_chunk ~ gameA_isSR + group_num_centered*avg_block_accuracy + factor(subj_id),
                           data = complete_data_rest_models_noRT)
fit.rest_noRT_seven <- glm.nb(num_rest_in_chunk ~ gameA_isSR + group_num_centered*avg_block_accuracy + factor(subj_id) + cue_type,
                           data = complete_data_rest_models_noRT)
fit.rest_noRT_eight <- glm.nb(num_rest_in_chunk ~ gameA_isSR + group_num_centered*avg_block_accuracy + factor(subj_id) + cue_type + cue_type:avg_block_accuracy,
                           data = complete_data_rest_models_noRT)

library(performance)
compare_performance(fit.rest_noRT_one, fit.rest_noRT_two, fit.rest_noRT_three, fit.rest_noRT_four, fit.rest_noRT_five, fit.rest_noRT_six,
                    fit.rest_noRT_seven,fit.rest_noRT_eight)

# model 7 seems to be the best
check_model(fit.rest_noRT_seven) # has some issues
summary(fit.rest_noRT_seven)

# Create diagnostic plots
library(DHARMa)
simulationOutput_7 <- simulateResiduals(fittedModel = fit.rest_noRT_seven)
plot(simulationOutput_7)

# Check for overdispersion
testDispersion(simulationOutput_7)


######################################
# THIS MODEL HAS PROBLEMS / singularity
fit.rest_noRT_glmerTest<- glmer(num_rest_in_chunk ~ block_num_centered + avg_block_accuracy + (1|subj_id),
                           data = complete_data_rest_models_noRT,
                           family = poisson,#because its a count
                           control = glmerControl(optimizer = "bobyqa"))

# number of observations per subject (30 each)
table(complete_data_rest_models_noRT$subj_id)
# check random effects variance
VarCorr(fit.rest_noRT_glmerTest) # very small between subject difference? should I not use mixed effects then

# trying GLMs without subject id because it accounts for so little
fit.rest_noRT_glm_one <- glm(num_rest_in_chunk ~ block_num_centered,
                         data = complete_data_rest_models_noRT,
                         family = poisson)
fit.rest_noRT_glm_two <- glm(num_rest_in_chunk ~ block_num_centered + avg_block_accuracy,
                         data = complete_data_rest_models_noRT,
                         family = poisson)
fit.rest_noRT_glm_three <- glm(num_rest_in_chunk ~ block_num_centered*avg_block_accuracy,
                         data = complete_data_rest_models_noRT,
                         family = poisson)
fit.rest_noRT_glm_four <- glm(num_rest_in_chunk ~ block_num_centered*avg_block_accuracy + gameA_isSR,
                         data = complete_data_rest_models_noRT,
                         family = poisson)
fit.rest_noRT_glm_five <- glm(num_rest_in_chunk ~ block_num_centered*avg_block_accuracy + gameA_isSR + cue_type,
                         data = complete_data_rest_models_noRT,
                         family = poisson)
fit.rest_noRT_glm_six <- glm(num_rest_in_chunk ~ block_num_centered*avg_block_accuracy + gameA_isSR + avg_block_accuracy:cue_type,
                         data = complete_data_rest_models_noRT,
                         family = poisson)
fit.rest_noRT_glm_seven <- glm(num_rest_in_chunk ~ block_num_centered*avg_block_accuracy + gameA_isSR + game_type + cue_type,
                         data = complete_data_rest_models_noRT,
                         family = poisson)
fit.rest_noRT_glm_eight <- glm(num_rest_in_chunk ~ block_num_centered*avg_block_accuracy + gameA_isSR + game_type*cue_type,
                         data = complete_data_rest_models_noRT,
                         family = poisson)
fit.rest_noRT_glm_nine <- glm(num_rest_in_chunk ~ group_num_centered*avg_block_accuracy + gameA_isSR + game_type*cue_type,
                         data = complete_data_rest_models_noRT,
                         family = poisson)
fit.rest_noRT_glm_ten <- glm(num_rest_in_chunk ~ group_num_centered*scale_accuracy + gameA_isSR + game_type*cue_type,
                         data = complete_data_rest_models_noRT,
                         family = poisson)
fit.rest_noRT_glm_11 <- glm(num_rest_in_chunk ~ group_num_centered*avg_block_accuracy + gameA_isSR + game_type*cue_type + subj_id,
                         data = complete_data_rest_models_noRT,
                         family = poisson)
fit.rest_noRT_glm_12 <- glm(num_rest_in_chunk ~ group_num_centered*scale_accuracy + gameA_isSR + game_type*cue_type + subj_id,
                         data = complete_data_rest_models_noRT,
                         family = poisson)

compare_performance(fit.rest_noRT_glm_one, fit.rest_noRT_glm_two, fit.rest_noRT_glm_three, fit.rest_noRT_glm_four, fit.rest_noRT_glm_five,fit.rest_noRT_glm_six,fit.rest_noRT_glm_seven,fit.rest_noRT_glm_eight,fit.rest_noRT_glm_nine,fit.rest_noRT_glm_ten,fit.rest_noRT_glm_11,fit.rest_noRT_glm_12)


# model 10 seems to be the best
check_model(fit.rest_noRT_glm_ten) # has some issues but less
summary(fit.rest_noRT_glm_ten)

``` 


```{r q1_analysis_models_rt}
# 2) filter out the timed out rows and do this
complete_data_rest_models <- df_all_blockwise %>%
  filter(!is.na(rt_sd))
complete_data_rest_models <- na.omit(complete_data_rest_models)

complete_data_rest_models$group_num_centered <- 
    as.vector(scale(complete_data_rest_models$group_num, center=TRUE, scale=FALSE))
complete_data_rest_models$block_num_centered <- 
    as.vector(scale(complete_data_rest_models$block_num, center=TRUE, scale=FALSE))

# trying GLMs without subject id because it accounts for so little
fit.rest_glm_one <- glm(num_rest_in_chunk ~ block_num_centered,
                         data = complete_data_rest_models,
                         family = poisson)
fit.rest_glm_two <- glm(num_rest_in_chunk ~ block_num_centered + avg_rt,
                         data = complete_data_rest_models,
                         family = poisson)
fit.rest_glm_three <- glm(num_rest_in_chunk ~ block_num_centered + avg_rt + rt_sd,
                         data = complete_data_rest_models,
                         family = poisson)
fit.rest_glm_four <- glm(num_rest_in_chunk ~ block_num_centered*rt_sd + avg_rt,
                         data = complete_data_rest_models,
                         family = poisson)
fit.rest_glm_five <- glm(num_rest_in_chunk ~ block_num_centered*rt_sd + avg_rt + gameA_isSR + cue_type,
                         data = complete_data_rest_models,
                         family = poisson)
fit.rest_glm_six <- glm(num_rest_in_chunk ~ block_num_centered*rt_sd + gameA_isSR + avg_rt + cue_type + avg_block_accuracy,
                         data = complete_data_rest_models,
                         family = poisson)
fit.rest_glm_seven <- glm(num_rest_in_chunk ~ block_num_centered + avg_block_accuracy*rt_sd + avg_rt + gameA_isSR + game_type + cue_type,
                         data = complete_data_rest_models,
                         family = poisson)
fit.rest_glm_eight <- glm(num_rest_in_chunk ~ block_num_centered*rt_sd + avg_block_accuracy:rt_sd + avg_rt + gameA_isSR + game_type + cue_type,
                         data = complete_data_rest_models,
                         family = poisson)
fit.rest_glm_nine <- glm(num_rest_in_chunk ~ group_num_centered*rt_sd + avg_rt + avg_block_accuracy:rt_sd + gameA_isSR + game_type*cue_type,
                         data = complete_data_rest_models,
                         family = poisson)
fit.rest_glm_ten <- glm(num_rest_in_chunk ~ group_num_centered*rt_sd + avg_rt + scale_accuracy + scale_accuracy:rt_sd + gameA_isSR + game_type*cue_type,
                         data = complete_data_rest_models,
                         family = poisson)
fit.rest_glm_11 <- glm(num_rest_in_chunk ~ group_num_centered + rt_sd + avg_rt + scale_accuracy + scale_accuracy:rt_sd + game_type*cue_type,
                         data = complete_data_rest_models,
                         family = poisson)
fit.rest_glm_12 <- glm(num_rest_in_chunk ~ group_num_centered + rt_sd + avg_rt + scale_accuracy + scale_accuracy:rt_sd + game_type:cue_type + game_type,
                         data = complete_data_rest_models,
                         family = poisson)
fit.rest_glm_13 <- glm(num_rest_in_chunk ~ group_num_centered + rt_sd + avg_rt + scale_accuracy + scale_accuracy:rt_sd + game_type + cue_type,
                         data = complete_data_rest_models,
                         family = poisson)
fit.rest_glm_14 <- glm(num_rest_in_chunk ~ group_num_centered + rt_sd + avg_rt + scale_accuracy + scale_accuracy:rt_sd + game_type:cue_type + cue_type,
                         data = complete_data_rest_models,
                         family = poisson)

compare_performance(fit.rest_glm_one, fit.rest_glm_two, fit.rest_glm_three, fit.rest_glm_four, fit.rest_glm_five,fit.rest_glm_six,fit.rest_glm_seven,fit.rest_glm_eight,fit.rest_glm_nine) #9 is best

compare_performance(fit.rest_glm_nine, fit.rest_glm_ten,fit.rest_glm_11,fit.rest_glm_12,fit.rest_glm_13,fit.rest_glm_14) #13 is best but only a tiny bit (AIC BIC)

# models 11 and 12 seem to be the best
check_model(fit.rest_glm_11) # has some issues but less
summary(fit.rest_glm_11)

check_model(fit.rest_glm_12) # has some issues but less
summary(fit.rest_glm_12)

### 12 removes cue_type as its own signal; test which model is better
anova(fit.rest_glm_12, fit.rest_glm_11, test = "Chisq")


summary(fit.rest_glm_11) # i think this is basically the same as 12
summary(fit.rest_glm_13)
```
NOTES: being better makes you rest more (non-sig), and being told you'll switch after makes you rest less (significant), and the larger the group (the longer it's been) the more you'll rest (significant)
- last point supports that taking rests is restful
- but first two points kind of go against that if we take on the classic literature about it???

# QUESTION 2:
2) When does task switching reduce fatigue, if ever? i.e. how does performance differ in the block following a switch vs a non-switch, and how long is the subsequent self-paced rest (in comparison)


1. compare average accuracy in the block:
	1. following a switch vs following a stay
	2. account for game_type, block_num, group_num, 1|subj_id
	3.  can use "switched" or "stayed" as a predictor (create this variable after isolating those blocks)
2. compare number of rests taken in the rest after the first switched block vs in the rest after the first stayed block
	1. will be complicated to wrangle this
	2. account for game_type, block_num, group_num, 1|subj_id
	3. can use "switched" or "stayed" as a predictor (create this variable after isolating those blocks)


``` {r data_loading}

```

``` {r data_loading}

```

``` {r data_loading}

```


# QUESTION 3:
3) Is task switching acted upon as rejuvenating? i.e. will rest time when cued that the next block will be a switch be less than when cued the next block will be a stay

1. compare rest length between switches to rest length between stays
	1. can use "switched" or "stayed" as a predictor (create this variable after isolating those blocks)

**model idea**: Rest Time (rests taken in a given chunk) ~ time(block_num) + game_type + group_num(represents place in experiment) + gameA_isSR(which order the games were in) + told_theyd_switch + (1|subject)


``` {r data_loading}

```

``` {r data_loading}

```

``` {r data_loading}

```
