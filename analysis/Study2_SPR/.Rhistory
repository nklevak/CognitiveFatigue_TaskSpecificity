mutate(
term = case_when(
term == "(Intercept)" ~ "Intercept",
term == "avg_block_accuracy" ~ "Avg Accuracy of Previous Block",
term == "gameA_isSRTRUE" ~ "Game A = Spatial Recall condition",
term == "game_typespatial_recall" ~ "Previous Block = Spatial Recall",
term == "cue_typeswitch" ~ "Game Switched This Block",
term == "avg_block_accuracy:cue_typeswitch" ~ "Prior Block Avg Accuracy X Game Switched",
term == "group_num" ~ "Block Number in Experiment",
TRUE ~ term  # Keep original if no match
)
)
ggplot(coef_data, aes(y = reorder(term, estimate), x = estimate)) +
geom_vline(xintercept = 0, linetype = "dashed", color = "gray50") +
geom_pointrange(aes(xmin = conf.low, xmax = conf.high, color = p.value < 0.05)) +
scale_color_manual(values = c("TRUE" = "black", "FALSE" = "gray60"),
labels = c("p â‰¥ 0.05", "p < 0.05"),
name = "Significance") +
labs(x = "Coefficient Estimate", y = NULL,
title = "Fixed Effects Coefficients of Model Predicting Average Accuracy of a Block",
subtitle = "With 95% Confidence Intervals") +
theme_minimal() +
theme(legend.position = "bottom",
axis.text.y = element_text(size = 11),
panel.grid.minor = element_blank())
### CCN GRAPH FINAL (used in extended abstract)
ggplot(model_data_q2, aes(x = avg_block_accuracy,
y = next_block_successes/(next_block_successes + next_block_failures),
color = cue_type)) +
geom_point(alpha = 0.2, position=position_jitter(0.05,0.05)) +
geom_smooth(method = "glm", method.args = list(family = "binomial"), linewidth = 1.2) +
labs(x = "Average Previous Epoch Accuracy",
y = "Average Following Epoch Accuracy",
color = "Game Switch Type") +
scale_color_manual(values = c("#0072B2", "#F2CF66"),
labels = c("Game stayed the same", "Game switched")) +
ggtitle("Switching tasks improves performance after low-efficacy epochs",
"Fitting simple binomials on raw participant data, by switch type") +
theme_minimal() +
theme(legend.position = "bottom",
plot.title = element_text(face = "bold", size = 16),
plot.subtitle = element_text(size = 14),
legend.title = element_text(face = "bold", size = 14),
legend.text = element_text(size = 12),
text = element_text(family = "Arial", size = 12),
axis.title = element_text(face = "bold", size = 14),
axis.text = element_text(size = 12),
panel.background = element_rect(fill = "white", color = NA),
plot.background = element_rect(fill = "white", color = NA))
#
# # Save the plot to a PNG file
# ggsave("1b_big.png", width = 10, height = 8.5, dpi = 300)
# making a model to see how switching impacts future accuracy when you bin the previous accuracy into "low", "medium", or "high" performance
df_all_blockwise_q2_binned_data <- df_all_blockwise %>%
group_by(subj_id) %>%
arrange(subj_id, block_num) %>%
mutate(post_cue_avg_accuracy = lead(avg_block_accuracy, default = NA),
scaled_post_cue_avg_accuracy = lead(scale_accuracy, default = NA),
following_block_rest = lead(num_rest_in_chunk, default=NA),
scaled_following_block_rest = lead(scale_rest, default = NA)) %>%
ungroup() %>%
mutate(acc_category = cut(avg_block_accuracy,
breaks = c(-Inf, 0.33, 0.66, Inf),
labels = c("Low", "Medium", "High"))) %>%
ungroup() %>%
filter(block_num !=30) %>%
mutate(next_block_successes = as.integer(post_cue_avg_accuracy * all_per_block),
next_block_failures = all_per_block - next_block_successes) %>%
mutate(transition_category = ifelse(rest_type %in% c("group_A_A", "group_B_B"),"stay_long", ifelse(rest_type %in% c("block_same_same"), "stay_short", "switch")))
# this just calculates the significance of the difference between each bin
mixed_model_binned_data <- glmer(cbind(next_block_successes, next_block_failures) ~ acc_category * cue_type + (1|subj_id),
family=binomial,
data = df_all_blockwise_q2_binned_data)
summary(mixed_model_binned_data)
anova(mixed_model_binned_data)
emm <- emmeans(mixed_model_binned_data, ~ cue_type | acc_category)
pairs(emm)
# Plot results with significance annotations
# First get the pairwise comparison results
contrasts <- pairs(emm)
contrast_df <- as.data.frame(contrasts)
# Create the sig_annotations data frame correctly
sig_annotations <- data.frame(
acc_category = c("Low", "Medium", "High"),
y_pos = c(0.95, 0.95, 0.95),  # Position for annotations (adjust as needed)
sig_symbol = case_when(
contrast_df$p.value < 0.001 ~ "***",
contrast_df$p.value < 0.01 ~ "**",
contrast_df$p.value < 0.05 ~ "*",
TRUE ~ "n.s."
)
)
# Calculate the max y-position for each category to place annotations above error bars
y_pos_data <- df_all_blockwise_q2_binned_data %>%
group_by(acc_category, cue_type) %>%
summarize(
mean_acc = mean(post_cue_avg_accuracy),
se = sd(post_cue_avg_accuracy)/sqrt(n())
) %>%
group_by(acc_category) %>%
summarize(max_y = max(mean_acc + se) + 0.05)  # Add a small offset
# Update the y_pos in sig_annotations
sig_annotations <- sig_annotations %>%
left_join(y_pos_data, by = "acc_category")
ggplot(df_all_blockwise_q2_binned_data, aes(x = acc_category, y = post_cue_avg_accuracy, color = cue_type, group = cue_type)) +
geom_point(alpha = 0.1, position = position_jitter(0.4)) +
stat_summary(
fun = mean,
geom = "line",
size = 1
) +
stat_summary(
fun = mean,
geom = "point",
size = 3
) +
stat_summary(
fun.data = mean_se,
geom = "errorbar",
width = 0.2
) +
# sig annotations
geom_text(data = sig_annotations,
aes(x = acc_category, y = max_y, label = sig_symbol),
inherit.aes = FALSE, size = 5) +
scale_color_manual(values = c("#0097DF", "#E99746"),
labels = c("Stay", "Switch")) +
labs(x = "Average Previous Epoch Accuracy",
y = "Average Following Epoch Accuracy",
color = "Trial Type") +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +
theme_classic() +
theme(
legend.position = "top",
axis.text = element_text(size = 10),
axis.title = element_text(size = 12),
legend.title = element_text(size = 12),
legend.text = element_text(size = 10)
) +
ggtitle("Switching tasks improves performance after low-efficacy epochs",
"Significance is based on the logistic mixed effects model results")
# model 1: basic random effect
fit.mixed_simple_1 <- glmer(cbind(next_block_successes, next_block_failures) ~ (1|subj_id),
family = binomial,
data = model_data_q2)
# model 2: avg_block_accuracy is a significant positive predictor
fit.mixed_simple_2 <- glmer(cbind(next_block_successes, next_block_failures) ~ avg_block_accuracy + (1|subj_id),
family = binomial,
data = model_data_q2)
# model 3: avg_block_accuracy is a significant positive predictor
fit.mixed_simple_3 <- glmer(cbind(next_block_successes, next_block_failures) ~ avg_block_accuracy + num_rest_in_chunk + (1|subj_id),
family = binomial,
data = model_data_q2)
# model 4: avg_block_accuracy is a significant positive predictor
fit.mixed_simple_4 <- glmer(cbind(next_block_successes, next_block_failures) ~ avg_block_accuracy + cue_type + num_rest_in_chunk + (1|subj_id),
family = binomial,
data = model_data_q2)
# model 5: avg_block_accuracy is a significant positive predictor; cue_typeswitch is a significant positive predictor;
# avg_block_accuracy:cue_typeswitch is a significant negative predicter
fit.mixed_simple_5 <- glmer(cbind(next_block_successes, next_block_failures) ~ avg_block_accuracy*cue_type + num_rest_in_chunk + (1|subj_id),
family = binomial,
data = model_data_q2)
# model 6: same as 5
fit.mixed_simple_6 <- glmer(cbind(next_block_successes, next_block_failures) ~ avg_block_accuracy*cue_type + num_rest_in_chunk + group_num + (1|subj_id),
family = binomial,
data = model_data_q2)
# model 7: same as 5
fit.mixed_simple_7 <- glmer(cbind(next_block_successes, next_block_failures) ~ avg_block_accuracy*cue_type + num_rest_in_chunk + group_num + gameA_isSR + (1|subj_id),
family = binomial,
data = model_data_q2)
# model 8: same as 5 but spatial recall also sig neg predictor
fit.mixed_simple_8 <- glmer(cbind(next_block_successes, next_block_failures) ~ avg_block_accuracy*cue_type + num_rest_in_chunk + group_num + gameA_isSR + game_type + (1|subj_id),
family = binomial,
data = model_data_q2)
# model 9: same as 5 but spatial recall also sig neg predictor
fit.mixed_simple_9 <- glmer(cbind(next_block_successes, next_block_failures) ~ avg_block_accuracy*cue_type + num_rest_in_chunk + group_num + gameA_isSR + game_type + (1 + game_type|subj_id),
family = binomial,
data = model_data_q2)
# model 10: cue type switch is a sig pos predictor, rest are same as above
fit.mixed_simple_10 <- glmer(cbind(next_block_successes, next_block_failures) ~ avg_block_accuracy*cue_type + group_num + game_type + (1|subj_id),
family = binomial,
data = model_data_q2)
# model 11: switch generally positive but doing well and then getting switched is more neg
fit.mixed_simple_11 <- glmer(cbind(next_block_successes, next_block_failures) ~ avg_block_accuracy + cue_type + group_num + game_type + avg_block_accuracy:rest_type + (1|subj_id),
family = binomial,
data = model_data_q2)
# model 14: added num_rest_in_chunk to see if it makes a difference (only diff between 14 and 15)
fit.mixed_simple_14 <- glmer(cbind(next_block_successes, next_block_failures) ~ avg_block_accuracy*cue_type + game_type + group_num + num_rest_in_chunk + gameA_isSR + (1 + game_type|subj_id),
family = binomial,
data = model_data_q2) # failed to converge
#model 15:
fit.mixed_simple_15 <- glmer(cbind(next_block_successes, next_block_failures) ~ avg_block_accuracy*cue_type + game_type + group_num + gameA_isSR + (1 + game_type|subj_id),
family = binomial,
data = model_data_q2)
### CCN GRAPH FINAL (used in extended abstract)
ggplot(model_data_q2, aes(x = avg_block_accuracy,
y = next_block_successes/(next_block_successes + next_block_failures),
color = cue_type)) +
geom_point(alpha = 0.2, position=position_jitter(0.05,0.05)) +
geom_smooth(method = "glm", method.args = list(family = "binomial"), linewidth = 1.2) +
labs(x = "Average Previous Epoch Accuracy",
y = "Average Following Epoch Accuracy",
color = "Game Switch Type") +
scale_color_manual(values = c("#0072B2", "#F2CF66"),
labels = c("Game stayed the same", "Game switched")) +
ggtitle("Switching tasks improves performance after low-efficacy epochs",
"Fitting simple binomials on raw participant data, by switch type") +
theme_minimal() +
theme(legend.position = "bottom",
plot.title = element_text(face = "bold", size = 16),
plot.subtitle = element_text(size = 14),
legend.title = element_text(face = "bold", size = 14),
legend.text = element_text(size = 12),
text = element_text(family = "Arial", size = 12),
axis.title = element_text(face = "bold", size = 14),
axis.text = element_text(size = 12),
panel.background = element_rect(fill = "white", color = NA),
plot.background = element_rect(fill = "white", color = NA))
#
# # Save the plot to a PNG file
# ggsave("1b_big.png", width = 10, height = 8.5, dpi = 300)
ggplot(df_all_blockwise_q2_binned_data, aes(x = acc_category, y = avg_rt, color = cue_type, group = cue_type)) +
geom_point(alpha = 0.1, position = position_jitter(0.4)) +
stat_summary(
fun = mean,
geom = "line",
size = 1
) +
stat_summary(
fun = mean,
geom = "point",
size = 3
) +
stat_summary(
fun.data = mean_se,
geom = "errorbar",
width = 0.2
) +
scale_color_manual(values = c("#0097DF", "#E99746"),
labels = c("Stay", "Switch")) +
labs(x = "Average Previous Epoch Accuracy",
y = "Average Following RT",
color = "Trial Type") +
theme_classic() +
theme(
legend.position = "top",
axis.text = element_text(size = 10),
axis.title = element_text(size = 12),
legend.title = element_text(size = 12),
legend.text = element_text(size = 10)
)+
ggtitle("Effect of task switching on RT depending on prior performance",
"Not accounting for individual subject RT differences")
#### accounting for subject differences
df_all_blockwise_q2_binned_data_rt <- df_all_blockwise_q2_binned_data %>%
group_by(subj_id) %>%
mutate(scale_rt = scale(avg_rt)) %>%
ungroup()
ggplot(df_all_blockwise_q2_binned_data_rt, aes(x = acc_category, y = scale_rt, color = cue_type, group = cue_type)) +
geom_point(alpha = 0.1, position = position_jitter(0.4)) +
stat_summary(
fun = mean,
geom = "line",
size = 1
) +
stat_summary(
fun = mean,
geom = "point",
size = 3
) +
stat_summary(
fun.data = mean_se,
geom = "errorbar",
width = 0.2
) +
scale_color_manual(values = c("#0097DF", "#E99746"),
labels = c("Stay", "Switch")) +
labs(x = "Average Previous Epoch Accuracy",
y = "Average Following RT",
color = "Trial Type") +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +
theme_classic() +
theme(
legend.position = "top",
axis.text = element_text(size = 10),
axis.title = element_text(size = 12),
legend.title = element_text(size = 12),
legend.text = element_text(size = 10)
)+
ggtitle("Effect of task switching on RT depending on prior performance",
"RT scaled per subject")
ggplot(df_all_blockwise_q2_binned_data_rt, aes(x = acc_category, y = scale_rt, color = cue_type, group = cue_type)) +
geom_point(alpha = 0.1, position = position_jitter(0.4)) +
stat_summary(
fun = mean,
geom = "line",
size = 1
) +
stat_summary(
fun = mean,
geom = "point",
size = 3
) +
stat_summary(
fun.data = mean_se,
geom = "errorbar",
width = 0.2
) +
scale_color_manual(values = c("#0097DF", "#E99746"),
labels = c("Stay", "Switch")) +
labs(x = "Average Previous Epoch Accuracy",
y = "Average Following RT",
color = "Trial Type") +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +
theme_classic() +
theme(
legend.position = "top",
axis.text = element_text(size = 10),
axis.title = element_text(size = 12),
legend.title = element_text(size = 12),
legend.text = element_text(size = 10)
)+
ggtitle("Effect of task switching on RT depending on prior performance",
"RT scaled per subject")
```
ggplot(df_all_blockwise_q2_binned_data, aes(x = acc_category, y = avg_rt, color = cue_type, group = cue_type)) +
geom_point(alpha = 0.1, position = position_jitter(0.4)) +
stat_summary(
fun = mean,
geom = "line",
size = 1
) +
stat_summary(
fun = mean,
geom = "point",
size = 3
) +
stat_summary(
fun.data = mean_se,
geom = "errorbar",
width = 0.2
) +
scale_color_manual(values = c("#0097DF", "#E99746"),
labels = c("Stay", "Switch")) +
labs(x = "Average Previous Epoch Accuracy",
y = "Average Following RT",
color = "Trial Type") +
theme_classic() +
theme(
legend.position = "top",
axis.text = element_text(size = 10),
axis.title = element_text(size = 12),
legend.title = element_text(size = 12),
legend.text = element_text(size = 10)
)+
ggtitle("Effect of task switching on RT depending on prior performance",
"Not accounting for individual subject RT differences")
#### accounting for subject differences
df_all_blockwise_q2_binned_data_rt <- df_all_blockwise_q2_binned_data %>%
group_by(subj_id) %>%
mutate(scale_rt = scale(avg_rt)) %>%
ungroup()
ggplot(df_all_blockwise_q2_binned_data_rt, aes(x = acc_category, y = scale_rt, color = cue_type, group = cue_type)) +
geom_point(alpha = 0.1, position = position_jitter(0.4)) +
stat_summary(
fun = mean,
geom = "line",
size = 1
) +
stat_summary(
fun = mean,
geom = "point",
size = 3
) +
stat_summary(
fun.data = mean_se,
geom = "errorbar",
width = 0.2
) +
scale_color_manual(values = c("#0097DF", "#E99746"),
labels = c("Stay", "Switch")) +
labs(x = "Average Previous Epoch Accuracy",
y = "Average Following RT",
color = "Trial Type") +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +
theme_classic() +
theme(
legend.position = "top",
axis.text = element_text(size = 10),
axis.title = element_text(size = 12),
legend.title = element_text(size = 12),
legend.text = element_text(size = 10)
)+
ggtitle("Effect of task switching on RT depending on prior performance",
"RT scaled per subject")
install.packages("simr")
library(simr)
sim_treat <- powerSim(fit.mixed_simple_15, nsim=100, test = fcompare(cbind(next_block_successes, next_block_failures)~avg_block_accuracy + cue_type + game_type + group_num + gameA_isSR ))
sim_treat
# Power curve to determine sample size needed for 80% power
pc_interaction_q2 <- powerCurve(
fit.mixed_simple_15,
test = fixed("avg_block_accuracy:cue_typeswitch", "lr"),
along = "subj_id",  # vary number of subjects
breaks = c(10, 20, 30, 40, 50, 60, 70, 84),  # sample sizes to test
nsim = 200  # more simulations for stability
)
# View results
print(pc_interaction_q2)
# Plot the power curve
plot(pc_interaction_q2)
# Find exact N for 80% power
summary(pc_interaction_q2)
# Power curve to determine sample size needed for 80% power
pc_interaction_q2 <- powerCurve(
fit.mixed_simple_15,
test = fixed("avg_block_accuracy:cue_typeswitch", "lr"),
along = "subj_id",  # vary number of subjects
within = "subj_id",
breaks = c(10, 20, 30, 40, 50, 60, 70, 84),  # sample sizes to test
nsim = 100  # more simulations for stability
)
# Power curve to determine sample size needed for 80% power
pc_interaction_q2 <- powerCurve(
fit.mixed_simple_15,
test = fixed("avg_block_accuracy:cue_typeswitch", "lr"),
along = "subj_id",  # vary number of subjects
within = "subj_id",
breaks = c(10, 20, 30, 40, 50, 60, 70, 84),  # sample sizes to test
nsim = 100  # more simulations for stability
)
# NOW run power curve
pc_interaction_q2 <- powerCurve(
fit.binary,
test = fixed("avg_block_accuracy:cue_typeswitch", "lr"),
along = "subj_id",
breaks = c(10, 20, 30, 40, 50, 60, 70, 84),
nsim = 100
)
# Power curve to determine sample size needed for 80% power
# Expand each row into individual binary trials
model_data_q2_binary <- model_data_q2 %>%
rowwise() %>%
mutate(
total_trials = next_block_successes + next_block_failures,
trial_data = list(
tibble(
success = c(rep(1, next_block_successes),
rep(0, next_block_failures))
)
)
) %>%
select(-next_block_successes, -next_block_failures, -total_trials) %>%
unnest(trial_data)
# Refit model with binary outcome
fit.binary <- glmer(
success ~ avg_block_accuracy * cue_type + game_type +
group_num + gameA_isSR + (1 + game_type | subj_id),
family = binomial,
data = model_data_q2_binary
)
# NOW run power curve
pc_interaction_q2 <- powerCurve(
fit.binary,
test = fixed("avg_block_accuracy:cue_typeswitch", "lr"),
along = "subj_id",
breaks = c(10, 20, 30, 40, 50, 60, 70, 84),
nsim = 100
)
# View results
print(pc_interaction_q2)
# Plot the power curve
plot(pc_interaction_q2)
# Find exact N for 80% power
summary(pc_interaction_q2)
summary(fit.mixed_simple_15)  # Original cbind version
summary(fit.binary)            # Binary version
# Compare key coefficients
fixef(fit.mixed_simple_15)
fixef(fit.binary)
# These should be nearly identical!
# Check random effects
VarCorr(fit.mixed_simple_15)
VarCorr(fit.binary)
# Make conservative estimate (use lower CI bound)
fit.binary_conservative <- fit.binary
fixef(fit.binary_conservative)["avg_block_accuracy:cue_typeswitch"] <- -2.29  # Lower CI bound
# Extend to simulate more subjects
fit_extended <- extend(
fit.binary_conservative,
along = "subj_id",
n = 150  # Simulate up to 150 subjects
)
# Power curve
pc_q2 <- powerCurve(
fit_extended,
test = fixed("avg_block_accuracy:cue_typeswitch", "lr"),
along = "subj_id",
breaks = c(20, 40, 60, 84, 100, 120, 150),
nsim = 200,
progress = TRUE
)
pc_q2_test <- powerCurve(
fit_extended,
test = fixed("avg_block_accuracy:cue_typeswitch", "z"),  # Faster
along = "subj_id",
breaks = c(20, 40, 60, 84, 90),  # Fewer points
nsim = 100,  # Fewer sims
progress = TRUE
)
print(pc_q2_test)
plot(pc_q2_test)
