{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: fit a 2 state heirarchical HMM on the data to detect fatigue vs not fatigue.\n",
    "\n",
    "Data to feed in: subject_data_for_HMM.json\n",
    "\n",
    "Data format:\n",
    "84 subjects\n",
    "\n",
    "subject_data = {\n",
    "    '1': {\n",
    "        'epoch_accuracy': [0.8, 0.7, 0.9, ...],  # 30 values (one value pxser block)\n",
    "        'post_epoch_post_cue_rest_duration': [2.1, 3.5, 1.8, ...],  # 30 values (one value per block)\n",
    "        'rest_cue_type': ['switch' or 'stay'] # if the cue before the rest period was switch or stay (basically this is the same as epoch_follows_task_switch but one row up)\n",
    "        'epoch_follows_task_switch': [1 if switch, 0 if stay], # if this block was a product of a task switch (first row has to be NA because it was neither)\n",
    "        'block_number': [1,1,1, 2,2,2, 3,3,3, ..., 10,10,10],\n",
    "        'epoch_within_block': [1,2,3, 1,2,3, 1,2,3, ..., 1,2,3],\n",
    "        'overall_epoch': [1,2,3,4,5,6,7,8,9, ..., 28,29,30],\n",
    "        'game_type': ['A','A','A', 'B','B','B', ...],\n",
    "        'pre_epoch_rest_duration': [previous rest duration for each epoch] # first row has to be NA because there was no previous rest duration\n",
    "    },\n",
    "    # ... for all 84 subjects\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import pytensor as pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "with open('subject_data_for_HMM.json', 'r') as f:\n",
    "    subject_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data: list of arrays, one per subject\n",
    "# emissions (what it's predicting)\n",
    "epoch_accuracies = [np.array(subj['epoch_accuracy']) for subj in subject_data.values()]\n",
    "rest_durations = [np.array(subj['post_epoch_post_cue_rest_duration']) for subj in subject_data.values()]\n",
    "\n",
    "# covariates (depends on these)\n",
    "overall_epoch = [np.array(subj['overall_epoch']) for subj in subject_data.values()]\n",
    "game_type = [np.array(subj['game_type']) for subj in subject_data.values()]\n",
    "game_type_numeric = [\n",
    "    np.array([0 if g == 'digit_span' else 1 for g in subj['game_type']])\n",
    "    for subj in subject_data.values()\n",
    "]\n",
    "\n",
    "rest_cue_type = [np.array(subj['rest_cue_type']) for subj in subject_data.values()]# later model as Predictors of Transition Probabilities\n",
    "epoch_follows_task_switch = [np.array(subj['epoch_follows_task_switch']) for subj in subject_data.values()]# later model as Predictors of Transition Probabilities\n",
    "\n",
    "# data about the dataset\n",
    "n_subjects = len(epoch_accuracies)\n",
    "lengths = [len(x) for x in epoch_accuracies]\n",
    "\n",
    "# concatenate all of the relevant vars as observations (the emissions)\n",
    "all_obs = [np.column_stack((acc, rest)) for acc, rest in zip(epoch_accuracies, rest_durations)]\n",
    "\n",
    "n_states = 2 # high fatigue, low fatigue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NominalVariable' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 68\u001b[0m\n\u001b[1;32m     51\u001b[0m     pm\u001b[38;5;241m.\u001b[39mPotential(\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobs_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     53\u001b[0m         logp_hmm(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m         )\n\u001b[1;32m     64\u001b[0m     )\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# --- Sampling ---\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m trace \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/FYP_2024/CognitiveFatigue_TaskSpecificity/.venv/lib/python3.9/site-packages/pymc/sampling/mcmc.py:679\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, model, **kwargs)\u001b[0m\n\u001b[1;32m    676\u001b[0m         auto_nuts_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    678\u001b[0m initial_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 679\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[43massign_step_methods\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTEP_METHODS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nuts_sampler \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpymc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(step, NUTS):\n",
      "File \u001b[0;32m~/Desktop/FYP_2024/CognitiveFatigue_TaskSpecificity/.venv/lib/python3.9/site-packages/pymc/sampling/mcmc.py:218\u001b[0m, in \u001b[0;36massign_step_methods\u001b[0;34m(model, step, methods, step_kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_gradient:\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 218\u001b[0m         \u001b[43mtg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_logp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mNotImplementedError\u001b[39;00m, tg\u001b[38;5;241m.\u001b[39mNullTypeGradError):\n\u001b[1;32m    220\u001b[0m         has_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FYP_2024/CognitiveFatigue_TaskSpecificity/.venv/lib/python3.9/site-packages/pytensor/gradient.py:607\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(cost, wrt, consider_constant, disconnected_inputs, add_names, known_grads, return_disconnected, null_gradients)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/FYP_2024/CognitiveFatigue_TaskSpecificity/.venv/lib/python3.9/site-packages/pytensor/gradient.py:1407\u001b[0m, in \u001b[0;36m_populate_grad_dict\u001b[0;34m(var_to_app_to_idx, grad_dict, wrt, cost_name)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/FYP_2024/CognitiveFatigue_TaskSpecificity/.venv/lib/python3.9/site-packages/pytensor/gradient.py:1407\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/FYP_2024/CognitiveFatigue_TaskSpecificity/.venv/lib/python3.9/site-packages/pytensor/gradient.py:1362\u001b[0m, in \u001b[0;36maccess_grad_cache\u001b[0;34m(var)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/FYP_2024/CognitiveFatigue_TaskSpecificity/.venv/lib/python3.9/site-packages/pytensor/gradient.py:1037\u001b[0m, in \u001b[0;36maccess_term_cache\u001b[0;34m(node)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/FYP_2024/CognitiveFatigue_TaskSpecificity/.venv/lib/python3.9/site-packages/pytensor/gradient.py:1037\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/FYP_2024/CognitiveFatigue_TaskSpecificity/.venv/lib/python3.9/site-packages/pytensor/gradient.py:1362\u001b[0m, in \u001b[0;36maccess_grad_cache\u001b[0;34m(var)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/FYP_2024/CognitiveFatigue_TaskSpecificity/.venv/lib/python3.9/site-packages/pytensor/gradient.py:1037\u001b[0m, in \u001b[0;36maccess_term_cache\u001b[0;34m(node)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/FYP_2024/CognitiveFatigue_TaskSpecificity/.venv/lib/python3.9/site-packages/pytensor/gradient.py:1037\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "    \u001b[0;31m[... skipping similar frames: access_grad_cache at line 1362 (16 times), <listcomp> at line 1037 (15 times), access_term_cache at line 1037 (15 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/FYP_2024/CognitiveFatigue_TaskSpecificity/.venv/lib/python3.9/site-packages/pytensor/gradient.py:1037\u001b[0m, in \u001b[0;36maccess_term_cache\u001b[0;34m(node)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/FYP_2024/CognitiveFatigue_TaskSpecificity/.venv/lib/python3.9/site-packages/pytensor/gradient.py:1037\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/FYP_2024/CognitiveFatigue_TaskSpecificity/.venv/lib/python3.9/site-packages/pytensor/gradient.py:1362\u001b[0m, in \u001b[0;36maccess_grad_cache\u001b[0;34m(var)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/FYP_2024/CognitiveFatigue_TaskSpecificity/.venv/lib/python3.9/site-packages/pytensor/gradient.py:1192\u001b[0m, in \u001b[0;36maccess_term_cache\u001b[0;34m(node)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/FYP_2024/CognitiveFatigue_TaskSpecificity/.venv/lib/python3.9/site-packages/pytensor/scan/op.py:2895\u001b[0m, in \u001b[0;36mL_op\u001b[0;34m(self, inputs, outs, dC_douts)\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NominalVariable' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# for now only include overall_epoch and game_type as covariates\n",
    "# and epoch_accuracies and rest_durations as emissions/observations\n",
    "\n",
    "# --- PyMC Model ---\n",
    "with pm.Model() as model:\n",
    "    # Group-level priors for regression coefficients (per state, per emission)\n",
    "    group_base_mu = pm.Normal('group_base_mu', mu=0, sigma=1, shape=(n_states, 2))\n",
    "    group_beta_game = pm.Normal('group_beta_game', mu=0, sigma=1, shape=(n_states, 2))\n",
    "    group_beta_time = pm.Normal('group_beta_time', mu=0, sigma=1, shape=(n_states, 2))\n",
    "    group_sigma = pm.HalfNormal('group_sigma', sigma=1, shape=(n_states, 2))\n",
    "\n",
    "    # Subject-level emission parameters\n",
    "    base_mu = pm.Normal('base_mu', mu=group_base_mu, sigma=1, shape=(n_subjects, n_states, 2))\n",
    "    beta_game = pm.Normal('beta_game', mu=group_beta_game, sigma=1, shape=(n_subjects, n_states, 2))\n",
    "    beta_time = pm.Normal('beta_time', mu=group_beta_time, sigma=1, shape=(n_subjects, n_states, 2))\n",
    "    sigma = pm.HalfNormal('sigma', sigma=group_sigma, shape=(n_subjects, n_states, 2))\n",
    "\n",
    "    # Shared initial state probabilities and transition matrix\n",
    "    pi = pm.Dirichlet('pi', a=np.ones(n_states))\n",
    "    A = pm.Dirichlet('A', a=np.ones((n_states, n_states)), shape=(n_states, n_states))\n",
    "\n",
    "    # --- HMM Forward Algorithm for Each Subject ---\n",
    "    def logp_hmm(obs, game, time, base_mu, beta_game, beta_time, sigma, pi, A):\n",
    "        n = obs.shape[0]\n",
    "        # Compute means for each emission, each state, each time\n",
    "        # shape: (n_obs, n_states, 2)\n",
    "        mu = (base_mu[None, :, :] +\n",
    "              beta_game[None, :, :] * game[:, None, None] +\n",
    "              beta_time[None, :, :] * time[:, None, None])\n",
    "\n",
    "        # For each time, for each state, compute logp of observed emissions\n",
    "        logp_states = []\n",
    "        for k in range(n_states):\n",
    "            logp_acc = pm.logp(pm.Normal.dist(mu=mu[:, k, 0], sigma=sigma[k, 0]), obs[:, 0])\n",
    "            logp_rest = pm.logp(pm.Normal.dist(mu=mu[:, k, 1], sigma=sigma[k, 1]), obs[:, 1])\n",
    "            logp_states.append(logp_acc + logp_rest)\n",
    "        logp_states = pm.math.stack(logp_states, axis=1)  # shape (n_obs, n_states)\n",
    "\n",
    "        # Forward algorithm\n",
    "        def scan_fn(logp_t, prev_alpha):\n",
    "            alpha = pm.math.logsumexp(prev_alpha + pm.math.log(A), axis=1) + logp_t\n",
    "            return alpha\n",
    "\n",
    "        alpha_0 = pm.math.log(pi) + logp_states[0]\n",
    "        alphas, _ = pt.scan(fn=scan_fn, sequences=logp_states[1:], outputs_info=alpha_0)\n",
    "        logp = pm.math.logsumexp(alphas[-1])\n",
    "        return logp\n",
    "\n",
    "    # Add a Potential for each subject\n",
    "    for i in range(n_subjects):\n",
    "        pm.Potential(\n",
    "            f'obs_{i}',\n",
    "            logp_hmm(\n",
    "                all_obs[i],\n",
    "                game_type_numeric[i],\n",
    "                overall_epoch[i],\n",
    "                base_mu[i],\n",
    "                beta_game[i],\n",
    "                beta_time[i],\n",
    "                sigma[i],\n",
    "                pi,\n",
    "                A\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "    # --- Sampling ---\n",
    "    trace = pm.sample(1000, tune=1000, target_accept=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ls",
   "language": "python",
   "name": "ls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
