{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ddd1f76-62b2-482c-8b95-ee0049294550",
   "metadata": {},
   "source": [
    "Will compare the three best models, pick the best one, check it, and then analyze how it relates to various covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06f47f5f-d6ba-4542-88e7-df3b421004c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7045b9ff-a580-40db-bae8-f56fb62e3f39",
   "metadata": {},
   "source": [
    "# load the original obs the models were tested on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56dd0533-b979-49de-bc4c-0f366aaa35b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded 84 subjects\n",
      "Pooled data shape: (2520, 2)\n",
      "Subject lengths: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]\n",
      "Pooled data shape: (2520, 2)\n",
      "Subject lengths: [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]\n"
     ]
    }
   ],
   "source": [
    "# Combine all subjects\n",
    "print(\"Loading data...\")\n",
    "with open(\"../cleaned_data_files/subject_data_for_HMM.json\", \"r\") as f:\n",
    "    subject_data = json.load(f)\n",
    "print(f\"Loaded {len(subject_data)} subjects\")\n",
    "\n",
    "test_subjects = list(subject_data.keys())#all subjects\n",
    "\n",
    "all_obs = []\n",
    "lengths = []\n",
    "for subject_id in test_subjects:\n",
    "    subj = subject_data[subject_id]\n",
    "    accuracy = np.array(subj['epoch_accuracy'])\n",
    "    rest_duration = np.array(subj['post_epoch_post_cue_rest_duration'])\n",
    "    obs = np.column_stack([accuracy, rest_duration])\n",
    "    all_obs.append(obs)\n",
    "    lengths.append(len(obs))\n",
    "pooled_obs = np.vstack(all_obs)\n",
    "print(f\"Pooled data shape: {pooled_obs.shape}\")\n",
    "print(f\"Subject lengths: {lengths}\")\n",
    "pooled_obs[:, 1] = pooled_obs[:, 1] / 20  # Scale rest to 0-1 range\n",
    "print(f\"Pooled data shape: {pooled_obs.shape}\")\n",
    "print(f\"Subject lengths: {lengths}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38107fce-cc3a-4969-8414-b0aae3e1dafc",
   "metadata": {},
   "source": [
    "# selecting best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99037a3a-ec38-4647-bb85-d847659f6a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved models...\n",
      "Loaded 2-state model\n",
      "Loaded 3-state model\n",
      "Loaded 4-state model\n",
      "Loaded 5-state model\n",
      "Loaded 6-state model\n"
     ]
    }
   ],
   "source": [
    "# Load all models\n",
    "models_dir = 'pooled_models'\n",
    "models_data = {}\n",
    "model_files = {\n",
    "    '2-state': 'max2s_complete_best_pooled_hmm_analysis.pkl',\n",
    "    '3-state': 'max3s_complete_best_pooled_hmm_analysis.pkl',\n",
    "    '4-state': 'max4s_complete_best_pooled_hmm_analysis.pkl', \n",
    "    '5-state': 'max5s_complete_best_pooled_hmm_analysis.pkl',\n",
    "    '5-state': 'max5s_complete_best_pooled_hmm_analysis.pkl',\n",
    "    '6-state': 'max6s_complete_best_pooled_hmm_analysis.pkl'\n",
    "}\n",
    "\n",
    "print(\"Loading saved models...\")\n",
    "for name, filename in model_files.items():\n",
    "    full_file = f\"{models_dir}/{filename}\"\n",
    "    try:\n",
    "        with open(full_file, 'rb') as f:\n",
    "            models_data[name] = pickle.load(f)\n",
    "        print(f\"Loaded {name} model\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {name}: {e}\")\n",
    "\n",
    "if not models_data:\n",
    "    print(\"No models loaded successfully!\")\n",
    "    \n",
    "# Extract key information\n",
    "comparison_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c04f1cd9-437d-484f-ac67-0273df4bd663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL COMPARISON SUMMARY\n",
      "==================================================\n",
      "\n",
      "2-STATE MODEL:\n",
      "  States: 2\n",
      "  Log-likelihood: 1629.4924888615164\n",
      "  Converged: True\n",
      "  Parameters: 19\n",
      "  AIC: -3220.98\n",
      "  BIC: -3110.18\n",
      "\n",
      "3-STATE MODEL:\n",
      "  States: 3\n",
      "  Log-likelihood: 3357.698192540759\n",
      "  Converged: True\n",
      "  Parameters: 32\n",
      "  AIC: -6651.40\n",
      "  BIC: -6464.77\n",
      "\n",
      "4-STATE MODEL:\n",
      "  States: 4\n",
      "  Log-likelihood: 5323.097546658393\n",
      "  Converged: True\n",
      "  Parameters: 47\n",
      "  AIC: -10552.20\n",
      "  BIC: -10278.09\n",
      "\n",
      "5-STATE MODEL:\n",
      "  States: 5\n",
      "  Log-likelihood: 5798.579243746978\n",
      "  Converged: True\n",
      "  Parameters: 64\n",
      "  AIC: -11469.16\n",
      "  BIC: -11095.91\n",
      "\n",
      "6-STATE MODEL:\n",
      "  States: 6\n",
      "  Log-likelihood: 6335.37871724057\n",
      "  Converged: True\n",
      "  Parameters: 83\n",
      "  AIC: -12504.76\n",
      "  BIC: -12020.70\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for name, data in models_data.items():\n",
    "    model = data['model']\n",
    "    \n",
    "    # Basic info\n",
    "    n_states = model.n_components\n",
    "    score = data.get('score', data.get('performance', {}).get('log_likelihood', 'Unknown'))\n",
    "    converged = model.monitor_.converged\n",
    "    \n",
    "    # Calculate parameters (for AIC/BIC)\n",
    "    n_params = (n_states * n_states +          # transition matrix\n",
    "               n_states * 2 * 2 +             # emission means (2 features)\n",
    "               n_states * 3 +                 # covariance params (full)\n",
    "               n_states - 1)                  # initial probs (n-1 free params)\n",
    "    \n",
    "    comparison_results[name] = {\n",
    "        'n_states': n_states,\n",
    "        'log_likelihood': score,\n",
    "        'converged': converged,\n",
    "        'n_params': n_params,\n",
    "        'model': model,\n",
    "        'data_context': data.get('data_context', {}),\n",
    "        'means': model.means_,\n",
    "        'transitions': model.transmat_\n",
    "    }\n",
    "    \n",
    "    # Calculate AIC and BIC\n",
    "    if isinstance(score, (int, float)):\n",
    "        aic = -2 * score + 2 * n_params\n",
    "        bic = -2 * score + np.log(2520) * n_params  # Assuming ~2520 observations\n",
    "        comparison_results[name]['aic'] = aic\n",
    "        comparison_results[name]['bic'] = bic\n",
    "    \n",
    "    print(f\"\\n{name.upper()} MODEL:\")\n",
    "    print(f\"  States: {n_states}\")\n",
    "    print(f\"  Log-likelihood: {score}\")\n",
    "    print(f\"  Converged: {converged}\")\n",
    "    print(f\"  Parameters: {n_params}\")\n",
    "    if isinstance(score, (int, float)):\n",
    "        print(f\"  AIC: {aic:.2f}\")\n",
    "        print(f\"  BIC: {bic:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f87cec7e-aeae-4aa4-b936-d9e5322ade83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL SELECTION CRITERIA\n",
      "==================================================\n",
      "Best by Log-Likelihood: 6-state\n",
      "Best by AIC (complexity penalty): 6-state\n",
      "Best by BIC (stronger penalty): 6-state\n",
      "\n",
      " 6-state model is best by both AIC and BIC\n"
     ]
    }
   ],
   "source": [
    "# Model selection based on information criteria\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL SELECTION CRITERIA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Find best model by different criteria\n",
    "valid_models = {name: data for name, data in comparison_results.items() \n",
    "               if isinstance(data['log_likelihood'], (int, float))}\n",
    "\n",
    "if valid_models:\n",
    "    best_ll = max(valid_models.keys(), key=lambda x: valid_models[x]['log_likelihood'])\n",
    "    best_aic = min(valid_models.keys(), key=lambda x: valid_models[x]['aic'])\n",
    "    best_bic = min(valid_models.keys(), key=lambda x: valid_models[x]['bic'])\n",
    "    \n",
    "    print(f\"Best by Log-Likelihood: {best_ll}\")\n",
    "    print(f\"Best by AIC (complexity penalty): {best_aic}\")\n",
    "    print(f\"Best by BIC (stronger penalty): {best_bic}\")\n",
    "    \n",
    "    # Check if they agree\n",
    "    if best_aic == best_bic:\n",
    "        print(f\"\\n {best_aic} model is best by both AIC and BIC\")\n",
    "    else:\n",
    "        print(f\"\\n AIC favors {best_aic}, BIC favors {best_bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77d2a288-9e98-4a99-b92f-6df3b6612f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STATE CHARACTERISTICS COMPARISON\n",
      "==================================================\n",
      "\n",
      "2-STATE - STATE MEANS:\n",
      "  STATE-1: accuracy=0.770, rest=4.3 trials\n",
      "  STATE-2: accuracy=0.657, rest=20.0 trials\n",
      "\n",
      "3-STATE - STATE MEANS:\n",
      "  FOCUSED: accuracy=0.913, rest=1.2 trials\n",
      "  INTERMEDIATE: accuracy=0.670, rest=6.4 trials\n",
      "  FATIGUE: accuracy=0.657, rest=20.0 trials\n",
      "\n",
      "4-STATE - STATE MEANS:\n",
      "  FOCUSED: accuracy=0.901, rest=1.0 trials\n",
      "  MILD-FATIGUE: accuracy=0.816, rest=6.2 trials\n",
      "  MODERATE-FATIGUE: accuracy=0.000, rest=6.7 trials\n",
      "  SEVERE-FATIGUE: accuracy=0.682, rest=20.0 trials\n",
      "\n",
      "5-STATE - STATE MEANS:\n",
      "  FOCUSED: accuracy=0.901, rest=1.0 trials\n",
      "  LIGHT-FATIGUE: accuracy=0.922, rest=4.5 trials\n",
      "  MILD-FATIGUE: accuracy=0.687, rest=8.2 trials\n",
      "  MODERATE-FATIGUE: accuracy=0.000, rest=8.8 trials\n",
      "  SEVERE-FATIGUE: accuracy=0.728, rest=20.0 trials\n",
      "\n",
      "6-STATE - STATE MEANS:\n",
      "  STATE-1: accuracy=0.896, rest=1.0 trials\n",
      "  STATE-2: accuracy=0.005, rest=5.4 trials\n",
      "  STATE-3: accuracy=0.629, rest=5.8 trials\n",
      "  STATE-4: accuracy=0.875, rest=6.4 trials\n",
      "  STATE-5: accuracy=1.000, rest=6.5 trials\n",
      "  STATE-6: accuracy=0.653, rest=20.0 trials\n",
      "\n",
      "======================================================================\n",
      "STATE USAGE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "2-STATE - TRANSITION PERSISTENCE:\n",
      "  State 0: 0.789 (78.9% stay)\n",
      "  State 1: 0.938 (93.8% stay)\n",
      "  States with reasonable persistence: 2/2\n",
      "\n",
      "3-STATE - TRANSITION PERSISTENCE:\n",
      "  State 0: 0.770 (77.0% stay)\n",
      "  State 1: 0.795 (79.5% stay)\n",
      "  State 2: 0.789 (78.9% stay)\n",
      "  States with reasonable persistence: 3/3\n",
      "\n",
      "4-STATE - TRANSITION PERSISTENCE:\n",
      "  State 0: 0.891 (89.1% stay)\n",
      "  State 1: 0.803 (80.3% stay)\n",
      "  State 2: 0.736 (73.6% stay)\n",
      "  State 3: 0.705 (70.5% stay)\n",
      "  States with reasonable persistence: 4/4\n",
      "\n",
      "5-STATE - TRANSITION PERSISTENCE:\n",
      "  State 0: 0.708 (70.8% stay)\n",
      "  State 1: 0.631 (63.1% stay)\n",
      "  State 2: 0.880 (88.0% stay)\n",
      "  State 3: 0.669 (66.9% stay)\n",
      "  State 4: 0.785 (78.5% stay)\n",
      "  States with reasonable persistence: 5/5\n",
      "\n",
      "6-STATE - TRANSITION PERSISTENCE:\n",
      "  State 0: 0.320 (32.0% stay)\n",
      "  State 1: 0.478 (47.8% stay)\n",
      "  State 2: 0.826 (82.6% stay)\n",
      "  State 3: 0.627 (62.7% stay)\n",
      "  State 4: 0.853 (85.3% stay)\n",
      "  State 5: 0.729 (72.9% stay)\n",
      "  States with reasonable persistence: 6/6\n"
     ]
    }
   ],
   "source": [
    "# Detailed state analysis\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STATE CHARACTERISTICS COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for name, data in comparison_results.items():\n",
    "    model = data['model']\n",
    "    n_states = data['n_states']\n",
    "    \n",
    "    print(f\"\\n{name.upper()} - STATE MEANS:\")\n",
    "    \n",
    "    # Convert rest back to original scale (assuming /20 scaling)\n",
    "    scaling_factor = data.get('data_context', {}).get('scaling_factor', 20)\n",
    "    \n",
    "    # Sort states by rest duration for consistent comparison\n",
    "    rest_means = model.means_[:, 1] * scaling_factor\n",
    "    state_order = np.argsort(rest_means)\n",
    "    \n",
    "    for idx, state_idx in enumerate(state_order):\n",
    "        acc = model.means_[state_idx, 0]\n",
    "        rest = rest_means[state_idx]\n",
    "        \n",
    "        # Assign interpretable names\n",
    "        if n_states == 3:\n",
    "            state_names = [\"FOCUSED\", \"INTERMEDIATE\", \"FATIGUE\"]\n",
    "        elif n_states == 4:\n",
    "            state_names = [\"FOCUSED\", \"MILD-FATIGUE\", \"MODERATE-FATIGUE\", \"SEVERE-FATIGUE\"]\n",
    "        elif n_states == 5:\n",
    "            state_names = [\"FOCUSED\", \"LIGHT-FATIGUE\", \"MILD-FATIGUE\", \"MODERATE-FATIGUE\", \"SEVERE-FATIGUE\"]\n",
    "        else:\n",
    "            state_names = [f\"STATE-{i+1}\" for i in range(n_states)]\n",
    "        \n",
    "        state_name = state_names[idx] if idx < len(state_names) else f\"STATE-{idx+1}\"\n",
    "        print(f\"  {state_name}: accuracy={acc:.3f}, rest={rest:.1f} trials\")\n",
    "\n",
    "# State usage analysis\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STATE USAGE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "#show transition patterns\n",
    "for name, data in comparison_results.items():\n",
    "    model = data['model']\n",
    "    print(f\"\\n{name.upper()} - TRANSITION PERSISTENCE:\")\n",
    "    \n",
    "    diagonal_values = np.diag(model.transmat_)\n",
    "    for i, persistence in enumerate(diagonal_values):\n",
    "        print(f\"  State {i}: {persistence:.3f} ({persistence*100:.1f}% stay)\")\n",
    "    \n",
    "    # Check for reasonable persistence\n",
    "    reasonable_states = np.sum((diagonal_values > 0.3) & (diagonal_values < 0.99))\n",
    "    print(f\"  States with reasonable persistence: {reasonable_states}/{len(diagonal_values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6de86589-1c96-4c28-9bc2-5cabbf6babde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State 0: 330 observations (13.1%)\n",
      "State 1: 416 observations (16.5%)\n",
      "State 2: 580 observations (23.0%)\n",
      "State 3: 381 observations (15.1%)\n",
      "State 4: 190 observations (7.5%)\n",
      "State 5: 623 observations (24.7%)\n",
      "Minimum accuracy in data: 0.0\n",
      "Observations with accuracy < 0.1: 260\n"
     ]
    }
   ],
   "source": [
    "# check how often 4 and 5 use the 0 accuracy states\n",
    "# How often is the problematic state used?\n",
    "predicted_states = models_data['6-state']['model'].predict(pooled_obs, lengths=lengths)\n",
    "state_counts = np.bincount(predicted_states, minlength=5)\n",
    "for i, count in enumerate(state_counts):\n",
    "    print(f\"State {i}: {count} observations ({count/len(predicted_states)*100:.1f}%)\")\n",
    "\n",
    "print(f\"Minimum accuracy in data: {pooled_obs[:, 0].min()}\")\n",
    "print(f\"Observations with accuracy < 0.1: {np.sum(pooled_obs[:, 0] < 0.1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0b1283-bcb2-4323-b1cf-e52d4ec16a4d",
   "metadata": {},
   "source": [
    "*Analyis: **5-state model** seems like its the best mathematically + is still interpretable, but **3-state model** seems like it has the best interpretability. 6-state model doesnt use all the states as equally and is also less interpretable.* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b202333-bcf4-43d3-96dc-d71d37cf0f4b",
   "metadata": {},
   "source": [
    "# 3-State model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73c6ac2-eee8-4150-8e04-ce6bf36df8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PDM Environment)",
   "language": "python",
   "name": "pdm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
